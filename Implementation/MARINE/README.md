# The MARINE model

This directory includes the implementation of the MARINE model, as well as the experiments to apply it to the coral reef and AK fish datasets.

**PLEASE NOTE:**

* Notebooks in the _Auxilliary_ folder in the _Implementation_ directory set up the datasets in the manner in which they are used in the notebooks implementing MARINE.

* Each notebook starts with a cell (or cells) which sets the parameters to use in the implementation, most notably:
  * Which dataset the model should be applied to.
  * Which DINOv2 backbone to use.
  * Whether to use motion-based frame selection (referred to as `motionAbsdiff` throughout the notebooks) or evenly spaced frames (referred to as `evenly`).
  * The number of frames to use for classification.
  * The locations of the datasets, as well as directories to save results.
 
---

The implementation of MARINE is organized in the following notebooks.

## Frame_selection.ipynb
Comprises the frame selection module of MARINE.

Iterates over videos in the selected dataset and saves the index of the selected frames using the preferred method (motion-based or evenly spaced).

## Embeddings.ipynb
Comprises the feature extraction module of MARINE.

Uses the selected DINOv2 backbone to obtain the classifier tokens for the selected frames of each video in the dataset.

## Classification.ipynb
Comprises the classifier head of MARINE.

Using the concatenated DINOv2 features of the selected frames of each video, trains a shallow classifier network using cross-validation for the binary AR task.

Applies the trained classifier to the test set of the selected dataset and saves prediction results.

## Results.ipynb
Collects results as presented in the thesis paper.

Takes the predictions generated by MARINE's classification head in different configurations (as well as predictions generated by the VideoMAE benchmark model) and generates tables and figures to compare the models' performance (both in the AR and AD tasks).
