{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMyu4FHailT8A4SY0mhFo3y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZsofiaK/masterthesis/blob/main/Implementation/Pipeline/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification (binary action recognition)"
      ],
      "metadata": {
        "id": "-JvN_Sh01GXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up requirements"
      ],
      "metadata": {
        "id": "zaYVIbZ2F5WY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up name dictionary for later ease of use.\n",
        "dataset_dict = {'fishClips' : 'Fish clips', 'AK-fish' : 'AK fish'}"
      ],
      "metadata": {
        "id": "-6SM6II0FnTh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the dataset, model and embedding specifics for the classification.\n",
        "\n",
        "dataset_name = 'fishClips'\n",
        "\n",
        "dataset_dir = dataset_dict[dataset_name]\n",
        "\n",
        "image_size = 448    # The size of the embedded images.\n",
        "\n",
        "frame_selection_method = 'motionAbsdiff_10'\n",
        "\n",
        "embedding_method = 'dinov2-vits14-clf'\n",
        "\n",
        "clf_name = 'ShallowNetwork'\n",
        "\n",
        "val_score = 'f1_score'  # Score to use during cross-validation.\n",
        "\n",
        "input_size = 3840   # Size of the input vectors (embeddings).\n",
        "\n",
        "seed = 23   # For reproducability in pseudo-randomness."
      ],
      "metadata": {
        "id": "MIJ71q9R1rOO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up parameters for cross validation.\n",
        "\n",
        "# Number of folds to use.\n",
        "cv_folds = 3\n",
        "\n",
        "# Parameter grids to use for the models.\n",
        "param_grid = { 'ShallowNetwork': {\n",
        "    'layers': [0, 1, 2],\n",
        "    'dropout_rate': [0.0, 0.25, 0.5],\n",
        "    'learning_rate': [0.01, 0.001, 0.0001],\n",
        "    'pos_threshold' : [0.1, 0.15, 0.2, 0.5],  # Threshold for turning sigmoid prediction to binary label.\n",
        "    'epochs': [50],\n",
        "    'batch_size': [32]\n",
        "}\n",
        "}"
      ],
      "metadata": {
        "id": "FK_Z8GzHtuIp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up folder to save outputs.\n",
        "import os\n",
        "\n",
        "output_dir = 'Output'\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "t-XaFHjLwsB7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMDvjWVA1Fxv",
        "outputId": "28378a6c-5016-4143-aab3-1a7512597e5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Drive.\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify data source\n",
        "data_source = f\"/content/drive/My Drive/UvA/M Thesis/Data/{dataset_dir}\"\n",
        "\n",
        "# Specify directory to copy to\n",
        "data_dir = f\"/content/{dataset_dir}\""
      ],
      "metadata": {
        "id": "LObn91mn17vm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the folder to destination\n",
        "import shutil\n",
        "shutil.copytree(data_source, data_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5E0xUoE9-Sjv",
        "outputId": "6dff87e5-1efe-4ea8-aef5-a5d1560bbaa8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Fish clips'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data"
      ],
      "metadata": {
        "id": "h1IvtxOKF_iV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "FRRNvH6N2HMK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load video embeddings and labels\n",
        "embeddings_dir = f'{data_dir}/Embeddings/{frame_selection_method}/{embedding_method}/{image_size}'\n",
        "clips_csv_path = f'{data_dir}/clips.csv'\n",
        "\n",
        "clips_df = pd.read_csv(clips_csv_path)\n",
        "\n",
        "nr_clips = len(clips_df)\n",
        "progress = 0\n",
        "\n",
        "X = []  # Embeddings\n",
        "y = []  # Labels\n",
        "video_names = []  # Video names for saving predictions\n",
        "\n",
        "not_found_embeddings = []\n",
        "\n",
        "for index, row in clips_df.iterrows():\n",
        "    video_name = row['video'].replace('.mp4', '')\n",
        "    label = row['label']\n",
        "\n",
        "    embedding_path = os.path.join(embeddings_dir, f\"{video_name}.npy\")\n",
        "\n",
        "    if os.path.exists(embedding_path):\n",
        "        embedding = np.load(embedding_path)\n",
        "\n",
        "        X.append(embedding)\n",
        "        y.append(label)\n",
        "\n",
        "        video_names.append(video_name)\n",
        "\n",
        "    else:\n",
        "      not_found_embeddings.append(video_name)\n",
        "\n",
        "    progress += 1\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    print(f'Number of videos: {nr_clips}')\n",
        "    print(f'Progress: {progress/nr_clips * 100:.2f}%')"
      ],
      "metadata": {
        "id": "TuOIIoVy2AC3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3407d092-ec09-470b-d6b9-57aa9c950ecb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of videos: 220\n",
            "Progress: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if all embeddings were successfully loaded.\n",
        "\n",
        "if len(not_found_embeddings) > 0:\n",
        "  print('Failed to find embeddings for:')\n",
        "\n",
        "  for video in not_found_embeddings:\n",
        "    print(video)\n",
        "\n",
        "else:\n",
        "  print('Success! All embeddings read.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbT6MVGK7vbX",
        "outputId": "2a3e2a58-8269-4139-8686-94fcfb382b20"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! All embeddings read.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if all embeddings have the required input size and remove the ones which do not.\n",
        "X_original = X.copy()\n",
        "y_original = y.copy()\n",
        "video_names_original = video_names.copy()\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "video_names = []\n",
        "\n",
        "for i, array in enumerate(X_original):\n",
        "  if len(array) == input_size:\n",
        "    X.append(array)\n",
        "    y.append(y_original[i])\n",
        "    video_names.append(video_names_original[i])"
      ],
      "metadata": {
        "id": "X9M-a9FjSTGu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if any embeddings had to be removed.\n",
        "print(f'{len(X_original)-len(X)} embeddings were removed due to incorrect embedding size.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XFITK_OUDT3",
        "outputId": "9e907f51-641a-42ae-e35d-77e6678463b2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 embeddings were removed due to incorrect embedding size.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting to numpy.\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "0Rgq195x26Xe"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train-test split\n",
        "X_train, X_test, y_train, y_test, video_names_train, video_names_test = train_test_split(\n",
        "    X, y, video_names, test_size=0.2, stratify=y, random_state=seed)"
      ],
      "metadata": {
        "id": "dn6NQE3a3Hdi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle class imbalance through class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
        "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}"
      ],
      "metadata": {
        "id": "59L6EKye3CCY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross-validate model"
      ],
      "metadata": {
        "id": "R30ljSCIHvQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## FUNCTIONS FOR MODEL CROSS-VALIDATION.\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.metrics import recall_score, accuracy_score, f1_score\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def create_shallow_network(input_dim, hidden_layers, dropout_rate, learning_rate):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Dense input layer with ReLu\n",
        "    model.add(Dense(10, input_dim=input_dim, activation='relu'))\n",
        "\n",
        "    # Dense hidden layers with ReLu and dropout\n",
        "    for _ in range(hidden_layers):\n",
        "        model.add(Dense(128, activation='relu'))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Dense output layer with sigmoid activation\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def crossval_shallow_network(n_splits, input_dim, X, y, params_grid, \\\n",
        "                             val_score = 'accuracy', verbose=False):\n",
        "\n",
        "  kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "  # Set up best result tracker for grid search loop\n",
        "  best_score = 0\n",
        "\n",
        "  best_params = {}\n",
        "\n",
        "  # Calculate number of runs for progress monitoring.\n",
        "  total_runs = 1\n",
        "\n",
        "  for params in params_grid.values():\n",
        "    total_runs *= len(params)\n",
        "\n",
        "  total_runs *= n_splits\n",
        "\n",
        "  progress = 0\n",
        "\n",
        "  # Grid search loop\n",
        "  for hidden_layers in params_grid['layers']:\n",
        "      for dropout_rate in params_grid['dropout_rate']:\n",
        "          for learning_rate in params_grid['learning_rate']:\n",
        "\n",
        "            scores = {threshold : [] for threshold in params_grid['pos_threshold']}\n",
        "\n",
        "            for train_index, test_index in kf.split(X):\n",
        "                X_train, X_test = X[train_index], X[test_index]\n",
        "                y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "                # Create and fit the model\n",
        "                model = create_shallow_network(input_dim, hidden_layers, \\\n",
        "                                                dropout_rate, learning_rate)\n",
        "\n",
        "                model.fit(X_train, y_train, epochs=10, verbose=0)\n",
        "\n",
        "                # Sigmoid output\n",
        "                y_pred_raw = model.predict(X_test)\n",
        "\n",
        "                # Predicted labels based on sigmoid output\n",
        "                for threshold in params_grid['pos_threshold']:\n",
        "                  y_pred = (y_pred_raw > threshold).astype(int).squeeze()\n",
        "\n",
        "                  # Calculate performance based on selected score\n",
        "                  if val_score == 'accuracy':\n",
        "                    score = accuracy_score(y_test, y_pred)\n",
        "\n",
        "                  elif val_score == 'recall':\n",
        "                    score = recall_score(y_test, y_pred)\n",
        "\n",
        "                  elif val_score == 'f1_score':\n",
        "                    score = f1_score(y_test, y_pred)\n",
        "\n",
        "                  else:\n",
        "                    print(f'ERROR: unexpected validation score {val_score}.')\n",
        "                    print('Select one of: accuracy, recall, f1_score')\n",
        "\n",
        "                  scores[threshold].append(score)\n",
        "\n",
        "                  progress += 1\n",
        "\n",
        "                  clear_output(wait=True)\n",
        "                  print(f'Cross-validation progress: {progress / total_runs * 100:.2f}%')\n",
        "\n",
        "                # Best average score across all folds\n",
        "                best_threshold = max(scores, key=lambda thr: np.mean(scores[thr]))\n",
        "                best_average_score = np.mean(scores[best_threshold])\n",
        "\n",
        "                # Check if current model settings beat the current best\n",
        "                if best_average_score > best_score:\n",
        "                    best_score = best_average_score\n",
        "                    best_params = {'hidden_layers': hidden_layers,\n",
        "                                  'dropout_rate': dropout_rate,\n",
        "                                  'learning_rate': learning_rate,\n",
        "                                  'pos_threshold': best_threshold}\n",
        "\n",
        "  # Print best parameters and their score\n",
        "  if verbose:\n",
        "    print(f\"\\nBest Score: {best_score:.4f}\")\n",
        "    print(\"Best Parameters:\", best_params)\n",
        "\n",
        "  return best_params"
      ],
      "metadata": {
        "id": "nvWC2RMgpMF6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up model dictionary for ease of reuse.\n",
        "# Only models which do not need cross-validation are included in this.\n",
        "# Models with cross-validation are handled on an individual basis.\n",
        "\n",
        "models_dict = {\n",
        "    'LogisticRegression' : LogisticRegression(max_iter=1000, class_weight=class_weights_dict),\n",
        "    'SVC-Linear' : SVC(class_weight='balanced', kernel='linear')\n",
        "    }\n",
        "\n",
        "# Models which do not need cross-validation.\n",
        "no_cross_val = list(models_dict.keys())"
      ],
      "metadata": {
        "id": "HKtjad033aFR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting model (with potential cross validation).\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# If model requires cross-validation.\n",
        "if clf_name not in no_cross_val:\n",
        "  if clf_name == 'ShallowNetwork':\n",
        "    best_params = crossval_shallow_network(cv_folds, input_size, X_train, \\\n",
        "                                           y_train, param_grid['ShallowNetwork'],\\\n",
        "                                           val_score = val_score, verbose=True)\n",
        "\n",
        "    model = create_shallow_network(input_size, best_params['hidden_layers'], \\\n",
        "                                 best_params['dropout_rate'], best_params['learning_rate'])\n",
        "\n",
        "  # Saving best hyperparameters for the model.\n",
        "  best_params_df = pd.DataFrame([best_params])\n",
        "\n",
        "  params_output_path = os.path.join(output_dir, 'Parameters')\n",
        "\n",
        "  os.makedirs(params_output_path, exist_ok=True)\n",
        "\n",
        "  params_csv_path = os.path.join(output_dir, f'Parameters/params_{dataset_name}_{frame_selection_method}_{embedding_method}_{clf_name}.csv')\n",
        "\n",
        "  best_params_df.to_csv(params_csv_path, index=False)\n",
        "\n",
        "# If model does not require cross-validation.\n",
        "else:\n",
        "  model = models_dict[clf_name]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE1joIrK3I6_",
        "outputId": "e54ab5ff-7b8b-43b1-8aca-8eb242ca023f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation progress: 100.00%\n",
            "\n",
            "Best Score: 0.4000\n",
            "Best Parameters: {'hidden_layers': 0, 'dropout_rate': 0.25, 'learning_rate': 0.01, 'pos_threshold': 0.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model on the training set.\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn0TwY8yIbhx",
        "outputId": "59beefec-37c2-40cd-e3c5-2ac503d9416a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 1s 6ms/step - loss: 9.4282 - accuracy: 0.5966\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f86f4ab24d0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "if clf_name == 'ShallowNetwork':\n",
        "  y_pred = (model.predict(X_test) > best_params['pos_threshold']).astype(int).squeeze()\n",
        "\n",
        "else:\n",
        "  y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "K0l4E-me3uwm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1048f16e-d4eb-41d8-f772-6fcdad8f25b1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare DataFrame with video names and predictions.\n",
        "predictions_df = pd.DataFrame({\n",
        "    'video': video_names_test,\n",
        "    'prediction': y_pred\n",
        "})\n",
        "\n",
        "# Create predictions output directory.\n",
        "pred_output_path = os.path.join(output_dir, 'Predictions')\n",
        "os.makedirs(params_output_path, exist_ok=True)\n",
        "\n",
        "# Save predictions.\n",
        "predictions_csv_path = os.path.join(output_dir, f'pred_{dataset_name}_{frame_selection_method}_{embedding_method}_{image_size}_{clf_name}.csv')\n",
        "predictions_df.to_csv(predictions_csv_path, index=False)"
      ],
      "metadata": {
        "id": "jSTHAae23wqp"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Producing classification report.\n",
        "report = classification_report(y_test, y_pred, target_names=['No attack', 'Attack'])\n",
        "\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_4E06J24Gm7",
        "outputId": "fb91899c-9748-46f5-9cc7-dd97df12c716"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   No attack       0.80      1.00      0.89        35\n",
            "      Attack       0.00      0.00      0.00         9\n",
            "\n",
            "    accuracy                           0.80        44\n",
            "   macro avg       0.40      0.50      0.44        44\n",
            "weighted avg       0.63      0.80      0.70        44\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "sgrL1o8JcD4c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy files to Drive.\n",
        "for file in os.listdir(output_dir):\n",
        "  source_dir = os.path.join(output_dir, file)\n",
        "\n",
        "  if '_' in file:\n",
        "    dataset = file.split('_')[1]\n",
        "    data_dir_name = dataset_dict[dataset]\n",
        "\n",
        "    drive_output_dir = f\"/content/drive/My Drive/UvA/M Thesis/Data/{data_dir_name}/Predictions\"\n",
        "\n",
        "    if not os.path.exists(drive_output_dir):\n",
        "      os.makedirs(drive_output_dir)\n",
        "\n",
        "    destination = f'{drive_output_dir}/{file}'\n",
        "\n",
        "    shutil.copy(source_dir, destination)"
      ],
      "metadata": {
        "id": "5ABTeEmc9UCw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "d88c5fde-330f-4af2-e35f-786d7afb004f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'output_dir' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-134cb7750e6a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Copy files to Drive.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0msource_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'output_dir' is not defined"
          ]
        }
      ]
    }
  ]
}