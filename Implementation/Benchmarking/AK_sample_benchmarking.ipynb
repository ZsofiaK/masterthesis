{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNnUloLgvkw8tkxN7sF5sPX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZsofiaK/masterthesis/blob/main/Implementation/Benchmarking/AK_sample_benchmarking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AK sample benchmarking\n",
        "\n",
        "Benchmarking MARINE on a representative sample of Animal Kingdom."
      ],
      "metadata": {
        "id": "-JvN_Sh01GXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up requirements"
      ],
      "metadata": {
        "id": "zaYVIbZ2F5WY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up dictionaries for later ease of use.\n",
        "dataset_dict = {'AK-sample' : 'AK sample'}\n",
        "\n",
        "input_sizes_dict = {'dinov2-vits14-clf' : 384, 'dinov2-vitg14-clf' : 1536,\n",
        "                    'dinov2-vits14-reg-clf' : 384, 'dinov2-vitg14-reg-clf' : 1536}"
      ],
      "metadata": {
        "id": "-6SM6II0FnTh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the dataset, model and embedding specifics for the classification.\n",
        "\n",
        "dataset_name = 'AK-sample'\n",
        "\n",
        "dataset_dir = dataset_dict[dataset_name]\n",
        "\n",
        "nr_classes = 140    # Number of classes in the AK dataset.\n",
        "\n",
        "image_size = 448    # The size of the embedded images.\n",
        "\n",
        "frame_selection_method = 'evenly_10'\n",
        "\n",
        "embedding_method = 'dinov2-vitg14-clf'\n",
        "\n",
        "clf_name = 'ShallowNetwork'\n",
        "\n",
        "seed = 23   # For reproducability in pseudo-randomness.\n",
        "\n",
        "nr_frames = int(frame_selection_method.split('_')[-1])\n",
        "\n",
        "input_size = input_sizes_dict[embedding_method] * nr_frames   # Size of the input vectors (embeddings)."
      ],
      "metadata": {
        "id": "MIJ71q9R1rOO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up parameters for cross validation.\n",
        "\n",
        "# Number of folds to use.\n",
        "cv_folds = 3\n",
        "\n",
        "# Parameter grids to use for the models.\n",
        "param_grid = { 'ShallowNetwork': {\n",
        "    'layers': [0, 1, 2, 3],\n",
        "    'dropout_rate': [0.0, 0.25, 0.5],\n",
        "    'learning_rate': [0.01, 0.001, 0.0001]\n",
        "}\n",
        "}"
      ],
      "metadata": {
        "id": "FK_Z8GzHtuIp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up folder to save outputs.\n",
        "import os\n",
        "\n",
        "output_dir = 'Output'\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "t-XaFHjLwsB7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMDvjWVA1Fxv",
        "outputId": "b039d5fc-d5c8-4b0d-ce47-503668b00083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Drive.\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify data source\n",
        "data_dir = f\"/content/drive/MyDrive/UvA/M Thesis/Data/{dataset_dir}\""
      ],
      "metadata": {
        "id": "LObn91mn17vm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data"
      ],
      "metadata": {
        "id": "h1IvtxOKF_iV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from IPython.display import clear_output\n",
        "import shutil"
      ],
      "metadata": {
        "id": "FRRNvH6N2HMK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify embedding locations\n",
        "embeddings_dir = f'{data_dir}/Embeddings/{embedding_method}/{image_size}'\n",
        "local_embeddings_dir = f'/content/{dataset_dir}/Embeddings/{embedding_method}/{image_size}'\n",
        "\n",
        "os.makedirs(local_embeddings_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "OlMCPLWjDxbD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy embeddings to runtime.\n",
        "from IPython.display import clear_output\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "video_dirs = os.listdir(embeddings_dir)\n",
        "nr_videos = len(video_dirs)\n",
        "\n",
        "# Function to copy a single video directory\n",
        "def copy_video_dir(video_dir):\n",
        "    video_dir_path = os.path.join(embeddings_dir, video_dir)\n",
        "    local_video_dir_path = os.path.join(local_embeddings_dir, video_dir)\n",
        "\n",
        "    shutil.copytree(video_dir_path, local_video_dir_path)\n",
        "\n",
        "    return video_dir\n",
        "\n",
        "if len(os.listdir(local_embeddings_dir)) < nr_videos:    # Only copy if not already done.\n",
        "  # Progress tracker\n",
        "  progress = 0\n",
        "\n",
        "  # Copy directories in parallel\n",
        "  with ThreadPoolExecutor(max_workers=8) as executor:\n",
        "      futures = [executor.submit(copy_video_dir, video_dir) for video_dir in video_dirs]\n",
        "\n",
        "      for future in futures:\n",
        "        future.result()  # Wait for each future to complete\n",
        "\n",
        "        progress += 1\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        print(f'Progress: {progress / nr_videos * 100:.2f}%')\n",
        "\n",
        "else:\n",
        "  print('Embeddings have already been copied.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1Eqf9zIqttP",
        "outputId": "7d75bf26-af79-405f-8a4f-ffef42c66e0b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings have already been copied.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify metadata tables.\n",
        "clips_csv_path = f'{data_dir}/clips.csv'\n",
        "frame_selection_path = f'{data_dir}/Selected frames/{dataset_name}_{frame_selection_method}.csv'\n",
        "\n",
        "clips_df = pd.read_csv(clips_csv_path)\n",
        "frames_df = pd.read_csv(frame_selection_path, index_col='video')"
      ],
      "metadata": {
        "id": "e27jTxyIhybz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load video embeddings and labels\n",
        "nr_clips = len(clips_df)\n",
        "progress = 0\n",
        "\n",
        "X_train = []  # Embeddings\n",
        "X_test = []\n",
        "y_train = []  # Labels\n",
        "y_test = []\n",
        "\n",
        "video_names_train = []  # Video names for saving predictions\n",
        "video_names_test = []\n",
        "\n",
        "not_found_embeddings = []\n",
        "\n",
        "for index, row in clips_df.iterrows():\n",
        "  skip_to_next = False\n",
        "\n",
        "  video_name = row['video'].replace('.mp4', '')\n",
        "  labels = [int(label) for label in eval(row['labels'])]    # Reading label numbers.\n",
        "\n",
        "  embedding_path = f'{local_embeddings_dir}/{video_name}'\n",
        "\n",
        "  if video_name in video_names_train or video_name in video_names_test:\n",
        "    continue      # Skip embeddings which have already been read.\n",
        "\n",
        "  if not os.path.exists(embedding_path):\n",
        "    not_found_embeddings.append((video_name, 'all'))\n",
        "\n",
        "    progress += 1\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    print(f'Number of videos: {nr_clips}')\n",
        "    print(f'Progress: {progress/nr_clips * 100:.2f}%')\n",
        "\n",
        "    continue\n",
        "\n",
        "  frames = eval(frames_df['frames'][f'{video_name}.mp4'])\n",
        "\n",
        "  embedding = []\n",
        "\n",
        "  for frame_idx in frames:\n",
        "    frame_embedding_path = f'{embedding_path}/{video_name}_{frame_idx}.npy'\n",
        "\n",
        "    if not os.path.exists(frame_embedding_path):\n",
        "      not_found_embeddings.append((video_name, frame_idx))\n",
        "\n",
        "      skip_to_next = True   # Skip to next video\n",
        "\n",
        "      break\n",
        "\n",
        "    try:\n",
        "      frame_embedding = np.load(frame_embedding_path)\n",
        "\n",
        "    except:\n",
        "      print(video_name, 'Unable to load an embedding.')\n",
        "      break\n",
        "\n",
        "    embedding.append(frame_embedding)\n",
        "\n",
        "  if skip_to_next:\n",
        "    progress += 1\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    print(f'Number of videos: {nr_clips}')\n",
        "    print(f'Progress: {progress/nr_clips * 100:.2f}%')\n",
        "\n",
        "    continue\n",
        "\n",
        "  # Concatenate frame embeddings into numpy feature array.\n",
        "  np_embedding = np.concatenate(embedding)\n",
        "\n",
        "  # Create labels array: length of the number of classes, with 1s in the positions\n",
        "  # which classes apply and 0s elsewhere.\n",
        "  labels_array = np.zeros(nr_classes, dtype=int)\n",
        "\n",
        "  positive_positions = [label - 1 for label in labels]    # Positions in which the labels array must contain a 1 (due to 0 indexing).\n",
        "\n",
        "  labels_array[positive_positions] = 1    # Setting the positive classes in the labels array.\n",
        "\n",
        "  # Append instance to the appropriate split.\n",
        "  if row['type'] == 'train':\n",
        "    X_train.append(np_embedding)\n",
        "    y_train.append(labels_array)\n",
        "    video_names_train.append(video_name)\n",
        "\n",
        "  elif row['type'] == 'test':\n",
        "    X_test.append(np_embedding)\n",
        "    y_test.append(labels_array)\n",
        "    video_names_test.append(video_name)\n",
        "\n",
        "  progress += 1\n",
        "\n",
        "  clear_output(wait=True)\n",
        "  print(f'Number of videos: {nr_clips}')\n",
        "  print(f'Progress: {progress/nr_clips * 100:.2f}%')"
      ],
      "metadata": {
        "id": "TuOIIoVy2AC3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6bb3534-b191-4c25-fcd2-0adcc95cc91a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of videos: 1000\n",
            "Progress: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if all embeddings were successfully loaded.\n",
        "if len(not_found_embeddings) > 0:\n",
        "  print(f' WARNING: Failed to find embeddings for {len(set(([item[0] for item in not_found_embeddings])))} videos.')\n",
        "\n",
        "else:\n",
        "  print('Success! All embeddings read.')"
      ],
      "metadata": {
        "id": "UbT6MVGK7vbX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e21c7159-4f9d-499a-86a7-88d59e62731b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! All embeddings read.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if all embeddings have the required input size and pad the ones which do not.\n",
        "X_train_original = X_train.copy()\n",
        "X_test_original = X_test.copy()\n",
        "y_train_original = y_train.copy()\n",
        "y_test_original = y_test.copy()\n",
        "video_names_train_original = video_names_train.copy()\n",
        "video_names_test_original = video_names_test.copy()\n",
        "\n",
        "X_train = []\n",
        "X_test = []\n",
        "y_train = []\n",
        "y_test = []\n",
        "video_names_train = []\n",
        "video_names_test = []\n",
        "\n",
        "padded_train = 0\n",
        "padded_test = 0\n",
        "\n",
        "for i, array in enumerate(X_train_original):\n",
        "  if len(array) == input_size:\n",
        "    X_train.append(array)\n",
        "\n",
        "  elif len(array) < input_size:\n",
        "    difference = input_size - len(array)\n",
        "\n",
        "    padding_size_beginning = difference // 2 + ((difference % 2) * 1)\n",
        "    padding_size_end = difference // 2\n",
        "\n",
        "    padded_array = np.pad(array, (padding_size_beginning, padding_size_end), \\\n",
        "                          mode='constant', constant_values=(0, 0))\n",
        "\n",
        "    X_train.append(padded_array)\n",
        "\n",
        "    padded_train += 1\n",
        "\n",
        "  y_train.append(y_train_original[i])\n",
        "  video_names_train.append(video_names_train_original[i])\n",
        "\n",
        "for i, array in enumerate(X_test_original):\n",
        "  if len(array) == input_size:\n",
        "    X_test.append(array)\n",
        "\n",
        "  elif len(array) < input_size:\n",
        "    difference = input_size - len(array)\n",
        "\n",
        "    padding_size_beginning = difference // 2 + ((difference % 2) * 1)\n",
        "    padding_size_end = difference // 2\n",
        "\n",
        "    padded_array = np.pad(array, (padding_size_beginning, padding_size_end), \\\n",
        "                           mode='constant', constant_values=(0, 0))\n",
        "\n",
        "    X_test.append(padded_array)\n",
        "\n",
        "    padded_test += 1\n",
        "\n",
        "  y_test.append(y_test_original[i])\n",
        "  video_names_test.append(video_names_test_original[i])"
      ],
      "metadata": {
        "id": "X9M-a9FjSTGu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if any embeddings had to be removed.\n",
        "print(f'{padded_train} embeddings were padded in training set due to incorrect embedding size.')\n",
        "print(f'{padded_test} embeddings were padded in test set due to incorrect embedding size.')"
      ],
      "metadata": {
        "id": "_XFITK_OUDT3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92394421-3c78-4907-a4c0-553065dc53eb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 embeddings were padded in training set due to incorrect embedding size.\n",
            "0 embeddings were padded in test set due to incorrect embedding size.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting to numpy.\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "UEX2lL9Rlj0G"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove classes which are not represented in the sample.\n",
        "\n",
        "# Identify label columns in the target arrays which only contain 0s.\n",
        "all_labels = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "zero_label_columns = np.all(all_labels == 0, axis=0)\n",
        "\n",
        "# Save these labels as a list.\n",
        "zero_labels = np.where(zero_label_columns)[0].tolist()\n",
        "\n",
        "zero_labels = sorted([label + 1 for label in zero_labels])    # Adjust for 0 indexing and sort.\n",
        "\n",
        "# Remove these columns from the target arrays.\n",
        "y_train = y_train[:, ~zero_label_columns]\n",
        "y_test = y_test[:, ~zero_label_columns]\n",
        "\n",
        "actual_nr_classes = y_train.shape[1]\n",
        "print(f'Actual number of classes: {actual_nr_classes}')\n",
        "print()\n",
        "\n",
        "print(f'New shape of target arrays:')\n",
        "print(f'Train: {y_train.shape}')\n",
        "print(f'Test: {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bL-8TqWiwkD",
        "outputId": "1476ea83-ad62-4b8c-ed42-9d3555d334a6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual number of classes: 93\n",
            "\n",
            "New shape of target arrays:\n",
            "Train: (797, 93)\n",
            "Test: (203, 93)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle class imbalance through class weights (stored in a numpy array).\n",
        "# For this, class weights will be defined as the inverse of their frequencies.\n",
        "\n",
        "all_labels = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "# Compute the frequency of each class\n",
        "class_frequencies = np.sum(all_labels, axis=0)\n",
        "\n",
        "# Compute the total number of samples\n",
        "n_samples = all_labels.shape[0]\n",
        "\n",
        "# Compute class weights as the inverse of class frequencies\n",
        "# Use epsilon as a smoothing parameter to avoid problems with 0 division.\n",
        "epsilon = 10e-6\n",
        "\n",
        "class_weights = n_samples / (actual_nr_classes * (class_frequencies + epsilon))\n",
        "\n",
        "# Create array of sample weights, which uses the maximum class weight of\n",
        "# each sample as their weight.\n",
        "\n",
        "# Initialize sample weights array as 1 for every sample.\n",
        "sample_weights = np.ones((y_train.shape[0],))\n",
        "\n",
        "for i in range(y_train.shape[0]):   # For each training instance\n",
        "    # Collect class weights which apply to this instance.\n",
        "    active_weights = [class_weights[j] for j in range(y_train.shape[1]) if y_train[i, j] == 1]\n",
        "\n",
        "    if active_weights:  # Check if there are any classes which apply.\n",
        "        sample_weights[i] = np.max(active_weights)"
      ],
      "metadata": {
        "id": "59L6EKye3CCY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross-validate model"
      ],
      "metadata": {
        "id": "R30ljSCIHvQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## FUNCTIONS FOR MODEL CROSS-VALIDATION.\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.metrics import average_precision_score\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Function to calculate mAP (taken directly from Animal Kingdom).\n",
        "def get_map(preds, labels):\n",
        "  \"\"\"\n",
        "  Compute mAP for multi-label case.\n",
        "  Args:\n",
        "      preds (numpy tensor): num_examples x num_classes.\n",
        "      labels (numpy tensor): num_examples x num_classes.\n",
        "  Returns:\n",
        "      mean_ap (int): final mAP score.\n",
        "  https://github.com/facebookresearch/SlowFast/blob/2090f2918ac1ce890fdacd8fda2e590a46d5c734/slowfast/utils/meters.py#L231\n",
        "  \"\"\"\n",
        "  preds = preds[:, ~(np.all(labels == 0, axis=0))]\n",
        "  labels = labels[:, ~(np.all(labels == 0, axis=0))]\n",
        "  aps = [0]\n",
        "  try:\n",
        "      aps = average_precision_score(labels, preds, average=None)\n",
        "  except ValueError:\n",
        "      print(\n",
        "          \"Average precision requires a sufficient number of samples \\\n",
        "          in a batch which are missing in this sample.\"\n",
        "      )\n",
        "  mean_ap = np.mean(aps)\n",
        "  return mean_ap\n",
        "\n",
        "def create_shallow_network(input_dim, hidden_layers, dropout_rate, learning_rate):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Dense input layer with ReLu\n",
        "    model.add(Dense(10, input_dim=input_dim, activation='relu'))\n",
        "\n",
        "    # Dense hidden layers with ReLu and dropout\n",
        "    for _ in range(hidden_layers):\n",
        "        model.add(Dense(128, activation='relu'))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Dense output layer with sigmoid activation\n",
        "    model.add(Dense(actual_nr_classes, activation='sigmoid'))\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def crossval_shallow_network(n_splits, input_dim, X, y, params_grid, \\\n",
        "                             verbose=False, random_state=seed):\n",
        "\n",
        "  kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "  # Set up best result tracker for grid search loop\n",
        "  best_score = 0\n",
        "\n",
        "  best_params = {}\n",
        "\n",
        "  # Calculate number of runs for progress monitoring.\n",
        "  total_runs = 1\n",
        "\n",
        "  for params in params_grid.values():\n",
        "    total_runs *= len(params)\n",
        "\n",
        "  total_runs *= n_splits\n",
        "\n",
        "  progress = 0\n",
        "\n",
        "  # Grid search loop\n",
        "  for hidden_layers in params_grid['layers']:\n",
        "      for dropout_rate in params_grid['dropout_rate']:\n",
        "          for learning_rate in params_grid['learning_rate']:\n",
        "\n",
        "            scores = []\n",
        "\n",
        "            for train_index, test_index in kf.split(X):\n",
        "                X_train, X_test = X[train_index], X[test_index]\n",
        "                y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "                # Create and fit the model\n",
        "                model = create_shallow_network(input_dim, hidden_layers, \\\n",
        "                                                dropout_rate, learning_rate)\n",
        "\n",
        "                model.fit(X_train, y_train, epochs=10, verbose=0)\n",
        "\n",
        "                # Sigmoid output\n",
        "                y_pred_raw = model.predict(X_test)\n",
        "\n",
        "                # Calculate mAP.\n",
        "                score = get_map(y_pred_raw, y_test)\n",
        "\n",
        "                scores.append(score)\n",
        "\n",
        "                progress += 1\n",
        "\n",
        "                clear_output(wait=True)\n",
        "                print(f'Cross-validation progress: {progress / total_runs * 100:.2f}%')\n",
        "\n",
        "            average_score = np.mean(scores)\n",
        "\n",
        "            # Check if current model settings beat the current best\n",
        "            if average_score > best_score:\n",
        "                best_score = average_score\n",
        "                best_params = {'hidden_layers': hidden_layers,\n",
        "                              'dropout_rate': dropout_rate,\n",
        "                              'learning_rate': learning_rate\n",
        "                               }\n",
        "\n",
        "  # Print best parameters and their score\n",
        "  if verbose:\n",
        "    print(f\"\\nBest Score: {best_score:.4f}\")\n",
        "    print(\"Best Parameters:\", best_params)\n",
        "\n",
        "  return best_params"
      ],
      "metadata": {
        "id": "nvWC2RMgpMF6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting model.\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "best_params = crossval_shallow_network(cv_folds, input_size, X_train, \\\n",
        "                                        y_train, param_grid['ShallowNetwork'],\\\n",
        "                                       verbose=True)\n",
        "\n",
        "model = create_shallow_network(input_size, best_params['hidden_layers'], \\\n",
        "                              best_params['dropout_rate'], best_params['learning_rate'])"
      ],
      "metadata": {
        "id": "NE1joIrK3I6_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fc675fa-39a0-4437-9cbd-25cc4fa79dfd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation progress: 100.00%\n",
            "\n",
            "Best Score: 0.2209\n",
            "Best Parameters: {'hidden_layers': 3, 'dropout_rate': 0.0, 'learning_rate': 0.001}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model on the training set.\n",
        "model.fit(X_train, y_train, sample_weight=sample_weights)"
      ],
      "metadata": {
        "id": "Nn0TwY8yIbhx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75387db2-3bdc-49c0-e9dd-dcd30259f836"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 2s 5ms/step - loss: 0.2531 - accuracy: 0.0213\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ecaf83a9570>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions.\n",
        "y_pred_raw = model.predict(X_test)"
      ],
      "metadata": {
        "id": "tMTqwQYe4EC5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a362acdc-1e1b-4d09-abd2-49b9448826da"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mAP.\n",
        "map = get_map(y_pred_raw, y_test)\n",
        "\n",
        "best_params['mAP'] = map\n",
        "\n",
        "print(f'Mean average precision: {map}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RnApChTY9wN",
        "outputId": "c26761e4-71c6-4a15-975d-f20d183068c8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean average precision: 0.0691082267683288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find best threshold to classify instance as positive for some label.\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "y_train_pred_raw = model.predict(X_train)\n",
        "\n",
        "thresholds = [i / 10 for i in range(1,10)]\n",
        "\n",
        "best_score = 0\n",
        "\n",
        "best_threshold = None\n",
        "\n",
        "for threshold in thresholds:\n",
        "  y_train_pred = (y_train_pred_raw > threshold).astype(int)\n",
        "\n",
        "  score = f1_score(y_train_pred, y_train, average='micro')\n",
        "\n",
        "  if score > best_score:\n",
        "    best_score = map\n",
        "\n",
        "    best_threshold = threshold\n",
        "\n",
        "best_params['pos_threshold'] = best_threshold\n",
        "\n",
        "print(f'Best threshold for micro accuracy: {best_threshold}')\n",
        "print(f'Score: {best_score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_gMhSK5VB3u",
        "outputId": "b2c73373-d9b2-4149-f068-fdf0c10ccc39"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 2ms/step\n",
            "Best threshold for micro accuracy: 0.5\n",
            "Score: 0.0691082267683288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving best hyperparameters.\n",
        "best_params_df = pd.DataFrame([best_params])\n",
        "\n",
        "params_output_path = os.path.join(output_dir, 'Parameters')\n",
        "\n",
        "os.makedirs(params_output_path, exist_ok=True)\n",
        "\n",
        "params_csv_path = os.path.join(output_dir, f'Parameters/params_{dataset_name}_{frame_selection_method}_{embedding_method}_{image_size}.csv')\n",
        "\n",
        "best_params_df.to_csv(params_csv_path, index=False)"
      ],
      "metadata": {
        "id": "o4u-3kZUATgz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictions and testing"
      ],
      "metadata": {
        "id": "yMXGX5HiBOcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save predictions for each instance of the test set."
      ],
      "metadata": {
        "id": "HwjnevSxD7Mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare DataFrame with video names and predictions.\n",
        "predictions_df = pd.DataFrame({\n",
        "    'video': video_names_test,\n",
        "    'prediction': [list(predictions) for predictions in y_pred_raw],\n",
        "    'labels' : [list(labels) for labels in y_test]\n",
        "})\n",
        "\n",
        "# Create predictions output directory.\n",
        "pred_output_path = os.path.join(output_dir, 'Predictions')\n",
        "os.makedirs(pred_output_path, exist_ok=True)\n",
        "\n",
        "# Save predictions.\n",
        "predictions_csv_path = os.path.join(pred_output_path, f'pred_{dataset_name}_{frame_selection_method}_{embedding_method}_{image_size}.csv')\n",
        "predictions_df.to_csv(predictions_csv_path, index=False)"
      ],
      "metadata": {
        "id": "jSTHAae23wqp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy prediction files to Drive.\n",
        "for file in os.listdir(f'{output_dir}/Predictions'):\n",
        "  source_file = os.path.join(f'{output_dir}/Predictions', file)\n",
        "\n",
        "  if file.startswith('pred'):   # Only consider prediction outputs.\n",
        "    drive_output_dir = f\"/content/drive/My Drive/UvA/M Thesis/Data/Results/Predictions\"\n",
        "\n",
        "    if not os.path.exists(drive_output_dir):\n",
        "      os.makedirs(drive_output_dir)\n",
        "\n",
        "    destination = f'{drive_output_dir}/{file}'\n",
        "\n",
        "    # Overwrite existing file.\n",
        "    if os.path.exists(destination):\n",
        "      os.remove(destination)\n",
        "\n",
        "    shutil.copy(source_file, destination)\n",
        "\n",
        "for file in os.listdir(f'{output_dir}/Parameters'):\n",
        "  source_file = os.path.join(f'{output_dir}/Parameters', file)\n",
        "\n",
        "  if file.startswith('params'):   # Only consider parameter outputs.\n",
        "    drive_output_dir = f\"/content/drive/My Drive/UvA/M Thesis/Data/Results/Parameters\"\n",
        "\n",
        "    if not os.path.exists(drive_output_dir):\n",
        "      os.makedirs(drive_output_dir)\n",
        "\n",
        "    destination = f'{drive_output_dir}/{file}'\n",
        "\n",
        "    # Overwrite existing file.\n",
        "    if os.path.exists(destination):\n",
        "      os.remove(destination)\n",
        "\n",
        "    shutil.copy(source_file, destination)"
      ],
      "metadata": {
        "id": "5ABTeEmc9UCw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification report on the complete test set"
      ],
      "metadata": {
        "id": "B6eZ4Eg9EKAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn sigmoid predictions into binary ones.\n",
        "y_pred = (y_pred_raw > best_params['pos_threshold']).astype(int)"
      ],
      "metadata": {
        "id": "pKqRVkms8oy9"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display metrics.\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(f'Mean average precision: {map * 100:.2f}%')\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IFiOrrMoclB",
        "outputId": "c1e6feb3-695f-41e4-ed47-b2452844ef6c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean average precision: 6.91%\n",
            "Accuracy: 3.45%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Producing classification report.\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# print(report)"
      ],
      "metadata": {
        "id": "R_4E06J24Gm7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56da867f-9def-4574-f0b4-61f8cda3d9f0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diagnostics"
      ],
      "metadata": {
        "id": "mgYiykibo1M_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show distribution of classes in the sample.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Number of samples for each label.\n",
        "samples_count = np.sum(all_labels, axis=0)\n",
        "\n",
        "sorted_counts = sorted(list(samples_count), reverse=True)\n",
        "\n",
        "# Generate bar chart\n",
        "plt.bar(np.arange(len(sorted_counts)), sorted_counts, color='cornflowerblue')\n",
        "plt.title('Distribution of Samples per Label')\n",
        "plt.xlabel('Label rank')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "WhZUNFNho28M",
        "outputId": "5b1db4cd-d392-4335-dfd5-bbc9d905093f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}