{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPd40pl06PXh3vs6rMchNHd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZsofiaK/masterthesis/blob/main/Implementation/Auxilliary/Setting_up_AK_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up AK sample\n",
        "This notebook collects a representative sample from the Animal Kingdom dataset, which is used to test MARINE against other models benchmarked on this dataset (MSQNet, CARe)."
      ],
      "metadata": {
        "id": "p1nbheSrWpbs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preliminaries"
      ],
      "metadata": {
        "id": "DoTm1RjK6SjJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "daMW_WjbWiTn"
      },
      "outputs": [],
      "source": [
        "# Set up notebook parameters\n",
        "dataset_dir = '/content/drive/MyDrive/UvA/M Thesis/Data/AK sample'    # Location of the sample dataset directory\n",
        "videos_source = '/content/drive/My Drive/UvA/M Thesis/Data/Animal_Kingdom_shortcut/action_recognition/dataset/video.tar.gz'   # Location of the AK dataset.\n",
        "max_sample_size = 1000    # Maximum size of the representative sample\n",
        "seed = 42   # Random seed for reproducability.\n",
        "AK_clips = f'{dataset_dir}/AK_AR_metadata.xlsx'   # Path to the original AK metadata file\n",
        "clips_save_path = f'{dataset_dir}/clips.csv'    # Path to save sample metadata file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqJmPx4p6T1s",
        "outputId": "0ea23fb6-eca4-4528-df97-62337ae33603"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset metadata"
      ],
      "metadata": {
        "id": "dSjlg8xg_Wb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read original dataset metadata.\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "full_og_clips_df = pd.read_excel(AK_clips, sheet_name='AR')\n",
        "\n",
        "# Extract relevant columns from the original metadata sheet.\n",
        "og_clips_df = full_og_clips_df[['video_id', 'type', 'labels']]\n",
        "\n",
        "# Convert labels from comma-separated strings to lists.\n",
        "og_clips_df['labels'] = og_clips_df['labels'].apply(lambda x: x.split(','))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EW1QiNN6eVV",
        "outputId": "12d77439-1a9e-4ad9-c917-515d15155a63"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-d4b45732fd61>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  og_clips_df['labels'] = og_clips_df['labels'].apply(lambda x: x.split(','))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Take random sample from dataset"
      ],
      "metadata": {
        "id": "xUqgJswpLQ3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AK_sample, _ = train_test_split(og_clips_df, stratify=og_clips_df['type'], \\\n",
        "                                   test_size=1-(max_sample_size/len(og_clips_df)), \\\n",
        "                                   random_state=seed)"
      ],
      "metadata": {
        "id": "HnoiaYZoG8Hq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm sample sizes.\n",
        "print('Final sample sizes')\n",
        "print('TOTAL:', len(AK_sample))\n",
        "print('Train:', len(AK_sample[AK_sample['type']=='train']))\n",
        "print('Test:', len(AK_sample[AK_sample['type']=='test']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o48mLE1UK76b",
        "outputId": "aa3d1d71-5799-4959-f0db-ab950682b68b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final sample sizes\n",
            "TOTAL: 1000\n",
            "Train: 797\n",
            "Test: 203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confirm distribution of sample\n",
        "Chi-squared test to confirm that distribution of labels in the sample is identical to that in Animal Kingdom.\n",
        "\n",
        "`NOTE:` it is important to realize that due to very small frequencies, some labels may be dropped from the sample (these are shown later). Distribution is tested only for the labels which remain.\n",
        "\n"
      ],
      "metadata": {
        "id": "qqWSkUOi_U8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save labels and counts from original and sample dataset.\n",
        "from collections import Counter\n",
        "\n",
        "og_labels = og_clips_df.explode('labels')['labels'].tolist()\n",
        "sample_labels = AK_sample.explode('labels')['labels'].tolist()\n",
        "\n",
        "counts_og = dict(Counter(og_labels))\n",
        "counts_sample = dict(Counter(sample_labels))"
      ],
      "metadata": {
        "id": "sTUFPQQC_kCm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "import numpy as np\n",
        "\n",
        "# Create list of unique labels in sample.\n",
        "labels = list(counts_sample.keys())\n",
        "\n",
        "# Prepare values for each sample, aligning by labels\n",
        "og_counts = [counts_og[label] for label in labels]\n",
        "sample_counts = [counts_sample[label] for label in labels]\n",
        "\n",
        "# Perform the chi-squared test\n",
        "chi2, p, dof, expected = chi2_contingency([og_counts, sample_counts])\n",
        "\n",
        "print(f\"Chi-squared Statistic: {chi2}, p-value: {p}\")\n",
        "print(f'Difference in distribution is significant: {p < 0.05}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4hX0frhS5fJ",
        "outputId": "833f415d-03b7-4f53-ad94-42a8435f3d08"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-squared Statistic: 85.13653364520921, p-value: 0.6806998907509849\n",
            "Difference in distribution is significant: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dropped_labels = [(label, count) for label, count in counts_og.items() \\\n",
        "                  if label not in counts_sample]\n",
        "\n",
        "if len(dropped_labels) > 0:\n",
        "  print('Warning:', len(dropped_labels), 'labels dropped.')\n",
        "  print(f'Maximum dropped count: {max([item[1] for item in dropped_labels])}')\n",
        "\n",
        "  # print('LABEL \\t ORIGINAL COUNT')\n",
        "  # for label, count in sorted(dropped_labels, key=lambda x: x[1], reverse=True):\n",
        "  #   print(f'{label} \\t {count}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgxfuVtzH3hZ",
        "outputId": "4556db1c-4ca7-4dd0-ee7c-6ed9019dadb5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: 47 labels dropped.\n",
            "Maximum dropped count: 76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save files\n",
        "Save metadata file to Drive."
      ],
      "metadata": {
        "id": "45hDbu9wNRBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change video column name for consistency with other datasets.\n",
        "AK_sample = AK_sample.rename(columns={'video_id': 'video'})\n",
        "\n",
        "# Save metadata file.\n",
        "AK_sample.to_csv(clips_save_path, index=False)"
      ],
      "metadata": {
        "id": "AR3oYyTlNQP7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy sample AK videos to sample directory."
      ],
      "metadata": {
        "id": "uVB-xTTiOAUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating video directory in runtime.\n",
        "import os\n",
        "\n",
        "runtime_dest_folder = '/content/Videos'\n",
        "\n",
        "# Create the destination folder if it does not exist\n",
        "os.makedirs(runtime_dest_folder, exist_ok=True)"
      ],
      "metadata": {
        "id": "fnhwk7cANkhp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract videos to runtime.\n",
        "import tarfile\n",
        "\n",
        "with tarfile.open(videos_source, 'r:gz') as file:\n",
        "    file.extractall(path=runtime_dest_folder)\n",
        "\n",
        "    print(\"Extraction completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7bhCb_TPtoD",
        "outputId": "bb7a109a-6882-42ed-9e7d-e892833d0692"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy relevant videos to drive.\n",
        "\n",
        "# Setting up directory for relevant videos.\n",
        "drive_clips_folder = f'{dataset_dir}/Clips'\n",
        "\n",
        "# Create the destination folder if it does not exist\n",
        "os.makedirs(drive_clips_folder, exist_ok=True)"
      ],
      "metadata": {
        "id": "83OB24wgQDhC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through the video IDs and move each relevant video file to Drive directory\n",
        "import shutil\n",
        "from IPython.display import clear_output\n",
        "\n",
        "not_found_videos = 0\n",
        "\n",
        "progress = 0\n",
        "\n",
        "nr_videos = len(AK_sample)\n",
        "\n",
        "for video_id in AK_sample['video_id']:\n",
        "    source_file = os.path.join(f'{runtime_dest_folder}/video', f'{video_id}.mp4')\n",
        "\n",
        "    destination_file = os.path.join(drive_clips_folder, f'{video_id}.mp4')\n",
        "\n",
        "    # Check if the file exists before trying to copy.\n",
        "    if os.path.exists(source_file):\n",
        "        # Check if file had already been copied to Drive.\n",
        "        if not os.path.exists(destination_file):\n",
        "          shutil.copy(source_file, destination_file)\n",
        "\n",
        "    else:\n",
        "        not_found_videos += 1\n",
        "\n",
        "    progress += 1\n",
        "    clear_output(wait=True)\n",
        "    print(f'Number of videos: {nr_videos}')\n",
        "    print(f'Progress: {progress / nr_videos * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrILdN3eQgj7",
        "outputId": "37b3cf4f-68fe-4444-f02d-ce1cd1af9f31"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of videos: 1000\n",
            "Progress: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if all relevant videos were found.\n",
        "if not_found_videos > 0:\n",
        "  print(f'WARNING: {len(not_found_videos)} videos not found.')\n",
        "\n",
        "else:\n",
        "  print('Successfully copied all sample videos!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orssJ8zNSLKK",
        "outputId": "7eca5686-3e4b-4ead-8cab-6725ac87f198"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully copied all sample videos!\n"
          ]
        }
      ]
    }
  ]
}