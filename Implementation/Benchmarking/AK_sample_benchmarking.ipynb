{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPBlp4U87dv+Lnockl1tfln",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZsofiaK/masterthesis/blob/main/Implementation/Benchmarking/AK_sample_benchmarking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AK sample benchmarking\n",
        "\n",
        "Benchmarking MARINE on a representative sample of Animal Kingdom."
      ],
      "metadata": {
        "id": "-JvN_Sh01GXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up requirements"
      ],
      "metadata": {
        "id": "zaYVIbZ2F5WY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up dictionaries for later ease of use.\n",
        "dataset_dict = {'AK-sample' : 'AK sample'}\n",
        "\n",
        "input_sizes_dict = {'dinov2-vits14-clf' : 384, 'dinov2-vitg14-clf' : 1536,\n",
        "                    'dinov2-vits14-reg-clf' : 384, 'dinov2-vitg14-reg-clf' : 1536}"
      ],
      "metadata": {
        "id": "-6SM6II0FnTh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the dataset, model and embedding specifics for the classification.\n",
        "\n",
        "dataset_name = 'AK-sample'\n",
        "\n",
        "dataset_dir = dataset_dict[dataset_name]\n",
        "\n",
        "nr_classes = 140    # Number of classes in the AK dataset.\n",
        "\n",
        "image_size = 448    # The size of the embedded images.\n",
        "\n",
        "frame_selection_method = 'motionAbsdiff_10'\n",
        "\n",
        "embedding_method = 'dinov2-vitg14-clf'\n",
        "\n",
        "clf_name = 'ShallowNetwork'\n",
        "\n",
        "seed = 23   # For reproducability in pseudo-randomness.\n",
        "\n",
        "nr_frames = int(frame_selection_method.split('_')[-1])\n",
        "\n",
        "input_size = input_sizes_dict[embedding_method] * nr_frames   # Size of the input vectors (embeddings)."
      ],
      "metadata": {
        "id": "MIJ71q9R1rOO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up parameters for cross validation.\n",
        "\n",
        "# Number of folds to use.\n",
        "cv_folds = 3\n",
        "\n",
        "# Parameter grids to use for the models.\n",
        "param_grid = { 'ShallowNetwork': {\n",
        "    'layers': [0, 1, 2, 3],\n",
        "    'dropout_rate': [0.0, 0.25, 0.5],\n",
        "    'learning_rate': [0.01, 0.001, 0.0001]\n",
        "}\n",
        "}"
      ],
      "metadata": {
        "id": "FK_Z8GzHtuIp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up folder to save outputs.\n",
        "import os\n",
        "\n",
        "output_dir = 'Output'\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "t-XaFHjLwsB7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMDvjWVA1Fxv",
        "outputId": "d07bb6d5-d0d7-4fe1-bd98-af38bb7d57b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Drive.\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify data source\n",
        "data_dir = f\"/content/drive/MyDrive/UvA/M Thesis/Data/{dataset_dir}\""
      ],
      "metadata": {
        "id": "LObn91mn17vm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data"
      ],
      "metadata": {
        "id": "h1IvtxOKF_iV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from IPython.display import clear_output\n",
        "import shutil"
      ],
      "metadata": {
        "id": "FRRNvH6N2HMK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify embedding locations\n",
        "embeddings_dir = f'{data_dir}/Embeddings/{embedding_method}/{image_size}'\n",
        "local_embeddings_dir = f'/content/{dataset_dir}/Embeddings/{embedding_method}/{image_size}'\n",
        "\n",
        "os.makedirs(local_embeddings_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "OlMCPLWjDxbD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy embeddings to runtime.\n",
        "from IPython.display import clear_output\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "video_dirs = os.listdir(embeddings_dir)\n",
        "nr_videos = len(video_dirs)\n",
        "\n",
        "# Function to copy a single video directory\n",
        "def copy_video_dir(video_dir):\n",
        "    video_dir_path = os.path.join(embeddings_dir, video_dir)\n",
        "    local_video_dir_path = os.path.join(local_embeddings_dir, video_dir)\n",
        "\n",
        "    shutil.copytree(video_dir_path, local_video_dir_path)\n",
        "\n",
        "    return video_dir\n",
        "\n",
        "if len(os.listdir(local_embeddings_dir)) < nr_videos:    # Only copy if not already done.\n",
        "  # Progress tracker\n",
        "  progress = 0\n",
        "\n",
        "  # Copy directories in parallel\n",
        "  with ThreadPoolExecutor(max_workers=8) as executor:\n",
        "      futures = [executor.submit(copy_video_dir, video_dir) for video_dir in video_dirs]\n",
        "\n",
        "      for future in futures:\n",
        "        future.result()  # Wait for each future to complete\n",
        "\n",
        "        progress += 1\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        print(f'Progress: {progress / nr_videos * 100:.2f}%')\n",
        "\n",
        "else:\n",
        "  print('Embeddings have already been copied.')"
      ],
      "metadata": {
        "id": "g1Eqf9zIqttP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "336fe5db-e140-410b-ad0b-44394742931c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings have already been copied.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify metadata tables.\n",
        "clips_csv_path = f'{data_dir}/clips.csv'\n",
        "frame_selection_path = f'{data_dir}/Selected frames/{dataset_name}_{frame_selection_method}.csv'\n",
        "\n",
        "clips_df = pd.read_csv(clips_csv_path)\n",
        "frames_df = pd.read_csv(frame_selection_path, index_col='video')"
      ],
      "metadata": {
        "id": "e27jTxyIhybz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load video embeddings and labels\n",
        "nr_clips = len(clips_df)\n",
        "progress = 0\n",
        "\n",
        "X_train = []  # Embeddings\n",
        "X_test = []\n",
        "y_train = []  # Labels\n",
        "y_test = []\n",
        "\n",
        "video_names_train = []  # Video names for saving predictions\n",
        "video_names_test = []\n",
        "\n",
        "not_found_embeddings = []\n",
        "\n",
        "for index, row in clips_df.iterrows():\n",
        "  skip_to_next = False\n",
        "\n",
        "  video_name = row['video'].replace('.mp4', '')\n",
        "  labels = [int(label) for label in eval(row['labels'])]    # Reading label numbers.\n",
        "\n",
        "  embedding_path = f'{local_embeddings_dir}/{video_name}'\n",
        "\n",
        "  if video_name in video_names_train or video_name in video_names_test:\n",
        "    continue      # Skip embeddings which have already been read.\n",
        "\n",
        "  if not os.path.exists(embedding_path):\n",
        "    not_found_embeddings.append((video_name, 'all'))\n",
        "\n",
        "    progress += 1\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    print(f'Number of videos: {nr_clips}')\n",
        "    print(f'Progress: {progress/nr_clips * 100:.2f}%')\n",
        "\n",
        "    continue\n",
        "\n",
        "  frames = eval(frames_df['frames'][f'{video_name}.mp4'])\n",
        "\n",
        "  embedding = []\n",
        "\n",
        "  for frame_idx in frames:\n",
        "    frame_embedding_path = f'{embedding_path}/{video_name}_{frame_idx}.npy'\n",
        "\n",
        "    if not os.path.exists(frame_embedding_path):\n",
        "      not_found_embeddings.append((video_name, frame_idx))\n",
        "\n",
        "      skip_to_next = True   # Skip to next video\n",
        "\n",
        "      break\n",
        "\n",
        "    try:\n",
        "      frame_embedding = np.load(frame_embedding_path)\n",
        "\n",
        "    except:\n",
        "      print(video_name, 'Unable to load an embedding.')\n",
        "      break\n",
        "\n",
        "    embedding.append(frame_embedding)\n",
        "\n",
        "  if skip_to_next:\n",
        "    progress += 1\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    print(f'Number of videos: {nr_clips}')\n",
        "    print(f'Progress: {progress/nr_clips * 100:.2f}%')\n",
        "\n",
        "    continue\n",
        "\n",
        "  # Concatenate frame embeddings into numpy feature array.\n",
        "  np_embedding = np.concatenate(embedding)\n",
        "\n",
        "  # Create labels array: length of the number of classes, with 1s in the positions\n",
        "  # which classes apply and 0s elsewhere.\n",
        "  labels_array = np.zeros(nr_classes, dtype=int)\n",
        "\n",
        "  positive_positions = [label - 1 for label in labels]    # Positions in which the labels array must contain a 1 (due to 0 indexing).\n",
        "\n",
        "  labels_array[positive_positions] = 1    # Setting the positive classes in the labels array.\n",
        "\n",
        "  # Append instance to the appropriate split.\n",
        "  if row['type'] == 'train':\n",
        "    X_train.append(np_embedding)\n",
        "    y_train.append(labels_array)\n",
        "    video_names_train.append(video_name)\n",
        "\n",
        "  elif row['type'] == 'test':\n",
        "    X_test.append(np_embedding)\n",
        "    y_test.append(labels_array)\n",
        "    video_names_test.append(video_name)\n",
        "\n",
        "  progress += 1\n",
        "\n",
        "  clear_output(wait=True)\n",
        "  print(f'Number of videos: {nr_clips}')\n",
        "  print(f'Progress: {progress/nr_clips * 100:.2f}%')"
      ],
      "metadata": {
        "id": "TuOIIoVy2AC3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea9c2129-56c9-4588-f8c6-a0ab42d21ab4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of videos: 1000\n",
            "Progress: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if all embeddings were successfully loaded.\n",
        "if len(not_found_embeddings) > 0:\n",
        "  print(f' WARNING: Failed to find embeddings for {len(set(([item[0] for item in not_found_embeddings])))} videos.')\n",
        "\n",
        "else:\n",
        "  print('Success! All embeddings read.')"
      ],
      "metadata": {
        "id": "UbT6MVGK7vbX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b606bc-638f-4ee6-ce3b-a2ea9aa6942d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! All embeddings read.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if all embeddings have the required input size and pad the ones which do not.\n",
        "X_train_original = X_train.copy()\n",
        "X_test_original = X_test.copy()\n",
        "y_train_original = y_train.copy()\n",
        "y_test_original = y_test.copy()\n",
        "video_names_train_original = video_names_train.copy()\n",
        "video_names_test_original = video_names_test.copy()\n",
        "\n",
        "X_train = []\n",
        "X_test = []\n",
        "y_train = []\n",
        "y_test = []\n",
        "video_names_train = []\n",
        "video_names_test = []\n",
        "\n",
        "padded_train = 0\n",
        "padded_test = 0\n",
        "\n",
        "for i, array in enumerate(X_train_original):\n",
        "  if len(array) == input_size:\n",
        "    X_train.append(array)\n",
        "\n",
        "  elif len(array) < input_size:\n",
        "    difference = input_size - len(array)\n",
        "\n",
        "    padding_size_beginning = difference // 2 + ((difference % 2) * 1)\n",
        "    padding_size_end = difference // 2\n",
        "\n",
        "    padded_array = np.pad(array, (padding_size_beginning, padding_size_end), \\\n",
        "                          mode='constant', constant_values=(0, 0))\n",
        "\n",
        "    X_train.append(padded_array)\n",
        "\n",
        "    padded_train += 1\n",
        "\n",
        "  y_train.append(y_train_original[i])\n",
        "  video_names_train.append(video_names_train_original[i])\n",
        "\n",
        "for i, array in enumerate(X_test_original):\n",
        "  if len(array) == input_size:\n",
        "    X_test.append(array)\n",
        "\n",
        "  elif len(array) < input_size:\n",
        "    difference = input_size - len(array)\n",
        "\n",
        "    padding_size_beginning = difference // 2 + ((difference % 2) * 1)\n",
        "    padding_size_end = difference // 2\n",
        "\n",
        "    padded_array = np.pad(array, (padding_size_beginning, padding_size_end), \\\n",
        "                           mode='constant', constant_values=(0, 0))\n",
        "\n",
        "    X_test.append(padded_array)\n",
        "\n",
        "    padded_test += 1\n",
        "\n",
        "  y_test.append(y_test_original[i])\n",
        "  video_names_test.append(video_names_test_original[i])"
      ],
      "metadata": {
        "id": "X9M-a9FjSTGu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if any embeddings had to be removed.\n",
        "print(f'{padded_train} embeddings were padded in training set due to incorrect embedding size.')\n",
        "print(f'{padded_test} embeddings were padded in test set due to incorrect embedding size.')"
      ],
      "metadata": {
        "id": "_XFITK_OUDT3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1ec60aa-3466-463d-dd31-a8cb541418c4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16 embeddings were padded in training set due to incorrect embedding size.\n",
            "3 embeddings were padded in test set due to incorrect embedding size.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting to numpy.\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "UEX2lL9Rlj0G"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove classes which are not represented in the sample.\n",
        "\n",
        "# Identify label columns in the target arrays which only contain 0s.\n",
        "all_labels = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "zero_label_columns = np.all(all_labels == 0, axis=0)\n",
        "\n",
        "# Save these labels as a list.\n",
        "zero_labels = np.where(zero_label_columns)[0].tolist()\n",
        "\n",
        "zero_labels = sorted([label + 1 for label in zero_labels])    # Adjust for 0 indexing and sort.\n",
        "\n",
        "# Remove these columns from the target arrays.\n",
        "y_train = y_train[:, ~zero_label_columns]\n",
        "y_test = y_test[:, ~zero_label_columns]\n",
        "\n",
        "actual_nr_classes = y_train.shape[1]\n",
        "print(f'Actual number of classes: {actual_nr_classes}')\n",
        "print()\n",
        "\n",
        "print(f'New shape of target arrays:')\n",
        "print(f'Train: {y_train.shape}')\n",
        "print(f'Test: {y_test.shape}')"
      ],
      "metadata": {
        "id": "-bL-8TqWiwkD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2eff8b0-fd2c-4d97-dff2-fc4a842c5e58"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual number of classes: 93\n",
            "\n",
            "New shape of target arrays:\n",
            "Train: (797, 93)\n",
            "Test: (203, 93)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle class imbalance through class weights (stored in a numpy array).\n",
        "# For this, class weights will be defined as the inverse of their frequencies.\n",
        "\n",
        "# Compute the frequency of each class\n",
        "class_frequencies = np.sum(y_train, axis=0)\n",
        "\n",
        "# Compute the total number of samples\n",
        "n_samples = y_train.shape[0]\n",
        "\n",
        "# Compute class weights as the inverse of class frequencies\n",
        "# Use epsilon as a smoothing parameter to avoid problems with 0 division.\n",
        "epsilon = 10e-6\n",
        "\n",
        "class_weights = n_samples / (actual_nr_classes * (class_frequencies + epsilon))\n",
        "\n",
        "# Create array of sample weights, which uses the maximum class weight of\n",
        "# each sample as their weight.\n",
        "\n",
        "# Initialize sample weights array as 1 for every sample.\n",
        "sample_weights = np.ones((y_train.shape[0],))\n",
        "\n",
        "for i in range(y_train.shape[0]):   # For each training instance\n",
        "    # Collect class weights which apply to this instance.\n",
        "    active_weights = [class_weights[j] for j in range(y_train.shape[1]) if y_train[i, j] == 1]\n",
        "\n",
        "    if active_weights:  # Check if there are any classes which apply.\n",
        "        sample_weights[i] = np.max(active_weights)"
      ],
      "metadata": {
        "id": "59L6EKye3CCY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross-validate model"
      ],
      "metadata": {
        "id": "R30ljSCIHvQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## FUNCTIONS FOR MODEL CROSS-VALIDATION.\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.metrics import average_precision_score\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Function to calculate mAP (taken directly from Animal Kingdom).\n",
        "def get_map(preds, labels):\n",
        "  \"\"\"\n",
        "  Compute mAP for multi-label case.\n",
        "  Args:\n",
        "      preds (numpy tensor): num_examples x num_classes.\n",
        "      labels (numpy tensor): num_examples x num_classes.\n",
        "  Returns:\n",
        "      mean_ap (int): final mAP score.\n",
        "  https://github.com/facebookresearch/SlowFast/blob/2090f2918ac1ce890fdacd8fda2e590a46d5c734/slowfast/utils/meters.py#L231\n",
        "  \"\"\"\n",
        "  preds = preds[:, ~(np.all(labels == 0, axis=0))]\n",
        "  labels = labels[:, ~(np.all(labels == 0, axis=0))]\n",
        "  aps = [0]\n",
        "  try:\n",
        "      aps = average_precision_score(labels, preds, average=None)\n",
        "  except ValueError:\n",
        "      print(\n",
        "          \"Average precision requires a sufficient number of samples \\\n",
        "          in a batch which are missing in this sample.\"\n",
        "      )\n",
        "  mean_ap = np.mean(aps)\n",
        "  return mean_ap\n",
        "\n",
        "def create_shallow_network(input_dim, hidden_layers, dropout_rate, learning_rate):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Dense input layer with ReLu\n",
        "    model.add(Dense(10, input_dim=input_dim, activation='relu'))\n",
        "\n",
        "    # Dense hidden layers with ReLu and dropout\n",
        "    for _ in range(hidden_layers):\n",
        "        model.add(Dense(128, activation='relu'))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Dense output layer with sigmoid activation\n",
        "    model.add(Dense(actual_nr_classes, activation='sigmoid'))\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def crossval_shallow_network(n_splits, input_dim, X, y, params_grid, \\\n",
        "                             verbose=False, random_state=seed):\n",
        "\n",
        "  kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "  # Set up best result tracker for grid search loop\n",
        "  best_score = 0\n",
        "\n",
        "  best_params = {}\n",
        "\n",
        "  # Calculate number of runs for progress monitoring.\n",
        "  total_runs = 1\n",
        "\n",
        "  for params in params_grid.values():\n",
        "    total_runs *= len(params)\n",
        "\n",
        "  total_runs *= n_splits\n",
        "\n",
        "  progress = 0\n",
        "\n",
        "  # Grid search loop\n",
        "  for hidden_layers in params_grid['layers']:\n",
        "      for dropout_rate in params_grid['dropout_rate']:\n",
        "          for learning_rate in params_grid['learning_rate']:\n",
        "\n",
        "            scores = []\n",
        "\n",
        "            for train_index, test_index in kf.split(X):\n",
        "                X_train, X_test = X[train_index], X[test_index]\n",
        "                y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "                # Create and fit the model\n",
        "                model = create_shallow_network(input_dim, hidden_layers, \\\n",
        "                                                dropout_rate, learning_rate)\n",
        "\n",
        "                model.fit(X_train, y_train, epochs=10, verbose=0)\n",
        "\n",
        "                # Sigmoid output\n",
        "                y_pred_raw = model.predict(X_test)\n",
        "\n",
        "                # Calculate mAP.\n",
        "                score = get_map(y_pred_raw, y_test)\n",
        "\n",
        "                scores.append(score)\n",
        "\n",
        "                progress += 1\n",
        "\n",
        "                clear_output(wait=True)\n",
        "                print(f'Cross-validation progress: {progress / total_runs * 100:.2f}%')\n",
        "\n",
        "            average_score = np.mean(scores)\n",
        "\n",
        "            # Check if current model settings beat the current best\n",
        "            if average_score > best_score:\n",
        "                best_score = average_score\n",
        "                best_params = {'hidden_layers': hidden_layers,\n",
        "                              'dropout_rate': dropout_rate,\n",
        "                              'learning_rate': learning_rate\n",
        "                               }\n",
        "\n",
        "  # Print best parameters and their score\n",
        "  if verbose:\n",
        "    print(f\"\\nBest Score: {best_score:.4f}\")\n",
        "    print(\"Best Parameters:\", best_params)\n",
        "\n",
        "  return best_params"
      ],
      "metadata": {
        "id": "nvWC2RMgpMF6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting model.\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "best_params = crossval_shallow_network(cv_folds, input_size, X_train, \\\n",
        "                                        y_train, param_grid['ShallowNetwork'],\\\n",
        "                                       verbose=True)\n",
        "\n",
        "model = create_shallow_network(input_size, best_params['hidden_layers'], \\\n",
        "                              best_params['dropout_rate'], best_params['learning_rate'])"
      ],
      "metadata": {
        "id": "NE1joIrK3I6_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d296399-39ee-4131-dc9e-c149830229e1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation progress: 100.00%\n",
            "\n",
            "Best Score: 0.2001\n",
            "Best Parameters: {'hidden_layers': 3, 'dropout_rate': 0.0, 'learning_rate': 0.001}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model on the training set.\n",
        "model.fit(X_train, y_train, sample_weight=sample_weights, epochs=10)"
      ],
      "metadata": {
        "id": "Nn0TwY8yIbhx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b9ef8f4-e8da-48c2-e586-7d59179d53f2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "25/25 [==============================] - 2s 5ms/step - loss: 0.2544 - accuracy: 0.0728\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1197 - accuracy: 0.0828\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0879 - accuracy: 0.1041\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0749 - accuracy: 0.1054\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.1142\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.1368\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.1920\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0534 - accuracy: 0.1731\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0520 - accuracy: 0.1769\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.1782\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b631e3c9ff0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions.\n",
        "y_pred_raw = model.predict(X_test)"
      ],
      "metadata": {
        "id": "tMTqwQYe4EC5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe68e621-6206-4d82-9615-7e8e712289b7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mAP.\n",
        "map = get_map(y_pred_raw, y_test)\n",
        "\n",
        "best_params['mAP'] = map\n",
        "\n",
        "print(f'Mean average precision: {map}')"
      ],
      "metadata": {
        "id": "_RnApChTY9wN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44cb28e4-e158-40bd-a05f-db3ee850144a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean average precision: 0.24600086538509766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find best threshold to classify instance as positive for some label.\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "y_train_pred_raw = model.predict(X_train)\n",
        "\n",
        "thresholds = [i / 10 for i in range(1,10)]\n",
        "\n",
        "best_score = 0\n",
        "\n",
        "best_threshold = None\n",
        "\n",
        "for threshold in thresholds:\n",
        "  y_train_pred = (y_train_pred_raw > threshold).astype(int)\n",
        "\n",
        "  score = f1_score(y_train_pred, y_train, average='micro')\n",
        "\n",
        "  if score > best_score:\n",
        "    best_score = map\n",
        "\n",
        "    best_threshold = threshold\n",
        "\n",
        "best_params['pos_threshold'] = best_threshold\n",
        "\n",
        "print(f'Best threshold for micro accuracy: {best_threshold}')\n",
        "print(f'Score: {best_score}')"
      ],
      "metadata": {
        "id": "e_gMhSK5VB3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b478d9ed-d414-4561-cf31-a8f02777d2ce"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 2ms/step\n",
            "Best threshold for micro accuracy: 0.6\n",
            "Score: 0.24600086538509766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving best hyperparameters.\n",
        "best_params_df = pd.DataFrame([best_params])\n",
        "\n",
        "params_output_path = os.path.join(output_dir, 'Parameters')\n",
        "\n",
        "os.makedirs(params_output_path, exist_ok=True)\n",
        "\n",
        "params_csv_path = os.path.join(output_dir, f'Parameters/params_{dataset_name}_{frame_selection_method}_{embedding_method}_{image_size}.csv')\n",
        "\n",
        "best_params_df.to_csv(params_csv_path, index=False)"
      ],
      "metadata": {
        "id": "o4u-3kZUATgz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictions and testing"
      ],
      "metadata": {
        "id": "yMXGX5HiBOcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save predictions for each instance of the test set."
      ],
      "metadata": {
        "id": "HwjnevSxD7Mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare DataFrame with video names and predictions.\n",
        "predictions_df = pd.DataFrame({\n",
        "    'video': video_names_test,\n",
        "    'prediction': [list(predictions) for predictions in y_pred_raw],\n",
        "    'labels' : [list(labels) for labels in y_test]\n",
        "})\n",
        "\n",
        "# Create predictions output directory.\n",
        "pred_output_path = os.path.join(output_dir, 'Predictions')\n",
        "os.makedirs(pred_output_path, exist_ok=True)\n",
        "\n",
        "# Save predictions.\n",
        "predictions_csv_path = os.path.join(pred_output_path, f'pred_{dataset_name}_{frame_selection_method}_{embedding_method}_{image_size}.csv')\n",
        "predictions_df.to_csv(predictions_csv_path, index=False)"
      ],
      "metadata": {
        "id": "jSTHAae23wqp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy prediction files to Drive.\n",
        "for file in os.listdir(f'{output_dir}/Predictions'):\n",
        "  source_file = os.path.join(f'{output_dir}/Predictions', file)\n",
        "\n",
        "  if file.startswith('pred'):   # Only consider prediction outputs.\n",
        "    drive_output_dir = f\"/content/drive/My Drive/UvA/M Thesis/Data/Results/Predictions\"\n",
        "\n",
        "    if not os.path.exists(drive_output_dir):\n",
        "      os.makedirs(drive_output_dir)\n",
        "\n",
        "    destination = f'{drive_output_dir}/{file}'\n",
        "\n",
        "    # Overwrite existing file.\n",
        "    if os.path.exists(destination):\n",
        "      os.remove(destination)\n",
        "\n",
        "    shutil.copy(source_file, destination)\n",
        "\n",
        "for file in os.listdir(f'{output_dir}/Parameters'):\n",
        "  source_file = os.path.join(f'{output_dir}/Parameters', file)\n",
        "\n",
        "  if file.startswith('params'):   # Only consider parameter outputs.\n",
        "    drive_output_dir = f\"/content/drive/My Drive/UvA/M Thesis/Data/Results/Parameters\"\n",
        "\n",
        "    if not os.path.exists(drive_output_dir):\n",
        "      os.makedirs(drive_output_dir)\n",
        "\n",
        "    destination = f'{drive_output_dir}/{file}'\n",
        "\n",
        "    # Overwrite existing file.\n",
        "    if os.path.exists(destination):\n",
        "      os.remove(destination)\n",
        "\n",
        "    shutil.copy(source_file, destination)"
      ],
      "metadata": {
        "id": "5ABTeEmc9UCw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification report on the complete test set"
      ],
      "metadata": {
        "id": "B6eZ4Eg9EKAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn sigmoid predictions into binary ones.\n",
        "y_pred = (y_pred_raw > best_params['pos_threshold']).astype(int)"
      ],
      "metadata": {
        "id": "pKqRVkms8oy9"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display metrics.\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(f'Mean average precision: {map * 100:.2f}%')\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%')"
      ],
      "metadata": {
        "id": "6IFiOrrMoclB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c10c4644-69e3-44a0-f682-a482c1d6d703"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean average precision: 24.60%\n",
            "Accuracy: 0.49%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Producing classification report.\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# print(report)"
      ],
      "metadata": {
        "id": "R_4E06J24Gm7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af852b9f-d02f-487d-f040-d1e00976ea3d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diagnostics"
      ],
      "metadata": {
        "id": "mgYiykibo1M_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show distribution of classes in the sample.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Number of samples for each label.\n",
        "samples_count = np.sum(all_labels, axis=0)\n",
        "\n",
        "sorted_counts = sorted(list(samples_count), reverse=True)\n",
        "\n",
        "# Generate bar chart\n",
        "plt.bar(np.arange(len(sorted_counts)), sorted_counts, color='cornflowerblue')\n",
        "plt.title('Distribution of Samples per Label')\n",
        "plt.xlabel('Label rank')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WhZUNFNho28M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "14aa1d40-7f93-4c9f-a960-dc766f69d3fd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}