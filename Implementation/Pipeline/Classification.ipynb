{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7+47/sI27BpCWQwY8sGEY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZsofiaK/masterthesis/blob/main/Implementation/Pipeline/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification (binary action recognition)"
      ],
      "metadata": {
        "id": "-JvN_Sh01GXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up requirements"
      ],
      "metadata": {
        "id": "zaYVIbZ2F5WY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up dictionaries for later ease of use.\n",
        "dataset_dict = {'fishClips' : 'Fish clips', 'AK-fish' : 'AK fish'}\n",
        "\n",
        "input_sizes_dict = {'dinov2-vits14-clf' : 384, 'dinov2-vitg14-clf' : 1536}"
      ],
      "metadata": {
        "id": "-6SM6II0FnTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the dataset, model and embedding specifics for the classification.\n",
        "\n",
        "dataset_name = 'AK-fish'\n",
        "\n",
        "dataset_dir = dataset_dict[dataset_name]\n",
        "\n",
        "image_size = 448    # The size of the embedded images.\n",
        "\n",
        "frame_selection_method = 'motionAbsdiff_10'\n",
        "\n",
        "embedding_method = 'dinov2-vits14-clf'\n",
        "\n",
        "clf_name = 'ShallowNetwork'\n",
        "\n",
        "val_score = 'roc_auc'  # Score to use during cross-validation.\n",
        "\n",
        "seed = 23   # For reproducability in pseudo-randomness.\n",
        "\n",
        "nr_frames = int(frame_selection_method.split('_')[-1])\n",
        "\n",
        "input_size = input_sizes_dict[embedding_method] * nr_frames   # Size of the input vectors (embeddings)."
      ],
      "metadata": {
        "id": "MIJ71q9R1rOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up parameters for cross validation.\n",
        "\n",
        "# Number of folds to use.\n",
        "cv_folds = 3\n",
        "\n",
        "# Parameter grids to use for the models.\n",
        "param_grid = { 'ShallowNetwork': {\n",
        "    'layers': [0, 1, 2, 3],\n",
        "    'dropout_rate': [0.0, 0.25, 0.5],\n",
        "    'learning_rate': [0.01, 0.001, 0.0001],\n",
        "    'pos_threshold' : [0.1, 0.15, 0.2, 0.5],  # Threshold for turning sigmoid prediction to binary label.\n",
        "    'epochs': [50],\n",
        "    'batch_size': [32]\n",
        "}\n",
        "}"
      ],
      "metadata": {
        "id": "FK_Z8GzHtuIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up folder to save outputs.\n",
        "import os\n",
        "\n",
        "output_dir = 'Output'\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "t-XaFHjLwsB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMDvjWVA1Fxv",
        "outputId": "0ee9d0fa-06b5-45e9-8262-ae3c77da949b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Drive.\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify data source\n",
        "data_source = f\"/content/drive/My Drive/UvA/M Thesis/Data/{dataset_dir}\"\n",
        "\n",
        "# Specify directory to copy to\n",
        "data_dir = f\"/content/{dataset_dir}\""
      ],
      "metadata": {
        "id": "LObn91mn17vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the folder to destination\n",
        "import shutil\n",
        "\n",
        "if not os.path.exists(data_dir):\n",
        "  shutil.copytree(data_source, data_dir)"
      ],
      "metadata": {
        "id": "5E0xUoE9-Sjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data"
      ],
      "metadata": {
        "id": "h1IvtxOKF_iV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from IPython.display import clear_output\n",
        "import shutil"
      ],
      "metadata": {
        "id": "FRRNvH6N2HMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load video embeddings and labels\n",
        "embeddings_dir = f'{data_dir}/Embeddings/{embedding_method}/{image_size}'\n",
        "clips_csv_path = f'{data_dir}/clips.csv'\n",
        "frame_selection_path = f'{data_dir}/Selected_frames/{dataset_name}_{frame_selection_method}.csv'\n",
        "\n",
        "clips_df = pd.read_csv(clips_csv_path)\n",
        "frames_df = pd.read_csv(frame_selection_path, index_col='video')\n",
        "\n",
        "nr_clips = len(clips_df)\n",
        "progress = 0\n",
        "\n",
        "X_train = []  # Embeddings\n",
        "X_test = []\n",
        "y_train = []  # Labels\n",
        "y_test = []\n",
        "\n",
        "video_names_train = []  # Video names for saving predictions\n",
        "video_names_test = []\n",
        "\n",
        "not_found_embeddings = []\n",
        "\n",
        "for index, row in clips_df.iterrows():\n",
        "    skip_to_next = False\n",
        "\n",
        "    video_name = row['video'].replace('.mp4', '')\n",
        "    label = row['label']\n",
        "\n",
        "    embedding_path = f'{embeddings_dir}/{video_name}'\n",
        "\n",
        "    if not os.path.exists(embedding_path):\n",
        "      not_found_embeddings.append((video_name, 'all'))\n",
        "      continue\n",
        "\n",
        "    frames = eval(frames_df['frames'][f'{video_name}.mp4'])\n",
        "\n",
        "    embedding = []\n",
        "\n",
        "    for frame_idx in frames:\n",
        "      frame_embedding_path = f'{embedding_path}/{video_name}_{frame_idx}.npy'\n",
        "\n",
        "      if not os.path.exists(frame_embedding_path):\n",
        "        not_found_embeddings.append((video_name, frame_idx))\n",
        "\n",
        "        skip_to_next = True   # Skip to next video\n",
        "\n",
        "        break\n",
        "\n",
        "      frame_embedding = np.load(frame_embedding_path)\n",
        "\n",
        "      embedding.append(frame_embedding)\n",
        "\n",
        "    if skip_to_next:\n",
        "      continue\n",
        "\n",
        "    np_embedding = np.concatenate(embedding)\n",
        "\n",
        "    if row['type'] == 'train':\n",
        "      X_train.append(embedding)\n",
        "      y_train.append(label)\n",
        "      video_names_train.append(video_name)\n",
        "\n",
        "    elif row['type'] == 'test':\n",
        "      X_test.append(embedding)\n",
        "      y_test.append(label)\n",
        "      video_names_test.append(video_name)\n",
        "\n",
        "    progress += 1\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    print(f'Number of videos: {nr_clips}')\n",
        "    print(f'Progress: {progress/nr_clips * 100:.2f}%')"
      ],
      "metadata": {
        "id": "TuOIIoVy2AC3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95d61721-81d8-4ab7-8dab-f89ddc9cfee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of videos: 887\n",
            "Progress: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if all embeddings were successfully loaded.\n",
        "if len(not_found_embeddings) > 0:\n",
        "  print(f' WARNING: Failed to find embeddings for {len(not_found_embeddings)} videos.')\n",
        "\n",
        "else:\n",
        "  print('Success! All embeddings read.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbT6MVGK7vbX",
        "outputId": "4aca78fa-bf8b-4c5d-f13b-ac79433389f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! All embeddings read.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if all embeddings have the required input size and remove the ones which do not.\n",
        "X_train_original = X_train.copy()\n",
        "X_test_original = X_test.copy()\n",
        "y_train_original = y_train.copy()\n",
        "y_test_original = y_test.copy()\n",
        "video_names_train_original = video_names_train.copy()\n",
        "video_names_test_original = video_names_test.copy()\n",
        "\n",
        "X_train = []\n",
        "X_test = []\n",
        "y_train = []\n",
        "y_test = []\n",
        "video_names_train = []\n",
        "video_names_test = []\n",
        "\n",
        "for i, array in enumerate(X_train_original):\n",
        "  if len(array) == input_size:\n",
        "    X_train.append(array)\n",
        "    y_train.append(y_train_original[i])\n",
        "    video_names_train.append(video_names_train_original[i])\n",
        "\n",
        "for i, array in enumerate(X_test_original):\n",
        "  if len(array) == input_size:\n",
        "    X_test.append(array)\n",
        "    y_test.append(y_test_original[i])\n",
        "    video_names_test.append(video_names_test_original[i])"
      ],
      "metadata": {
        "id": "X9M-a9FjSTGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if any embeddings had to be removed.\n",
        "print(f'{len(X_train_original)-len(X_train)} embeddings were removed from training set due to incorrect embedding size.')\n",
        "print(f'{len(X_test_original)-len(X_test)} embeddings were removed from test set due to incorrect embedding size.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XFITK_OUDT3",
        "outputId": "7d8d5715-7eff-4822-900e-4f22679da25d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 embeddings were removed from training set due to incorrect embedding size.\n",
            "2 embeddings were removed from test set due to incorrect embedding size.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting to numpy.\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "0Rgq195x26Xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle class imbalance through class weights\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "all_labels = np.concatenate((y_train, y_test))\n",
        "\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(all_labels), y=all_labels)\n",
        "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "print('Class weights:')\n",
        "print(class_weights_dict)"
      ],
      "metadata": {
        "id": "59L6EKye3CCY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84f70bf4-8e86-4e98-8eea-1dbf982ae3ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights:\n",
            "{0: 0.550625, 1: 5.438271604938271}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross-validate model"
      ],
      "metadata": {
        "id": "R30ljSCIHvQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## FUNCTIONS FOR MODEL CROSS-VALIDATION.\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.metrics import recall_score, accuracy_score, f1_score, roc_auc_score\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def create_shallow_network(input_dim, hidden_layers, dropout_rate, learning_rate):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Dense input layer with ReLu\n",
        "    model.add(Dense(10, input_dim=input_dim, activation='relu'))\n",
        "\n",
        "    # Dense hidden layers with ReLu and dropout\n",
        "    for _ in range(hidden_layers):\n",
        "        model.add(Dense(128, activation='relu'))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Dense output layer with sigmoid activation\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def crossval_shallow_network(n_splits, input_dim, X, y, params_grid, \\\n",
        "                             val_score = 'accuracy', verbose=False):\n",
        "\n",
        "  kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "  # Set up best result tracker for grid search loop\n",
        "  best_score = 0\n",
        "\n",
        "  best_params = {}\n",
        "\n",
        "  # Calculate number of runs for progress monitoring.\n",
        "  total_runs = 1\n",
        "\n",
        "  for params in params_grid.values():\n",
        "    total_runs *= len(params)\n",
        "\n",
        "  total_runs *= n_splits\n",
        "\n",
        "  progress = 0\n",
        "\n",
        "  # Grid search loop\n",
        "  for hidden_layers in params_grid['layers']:\n",
        "      for dropout_rate in params_grid['dropout_rate']:\n",
        "          for learning_rate in params_grid['learning_rate']:\n",
        "\n",
        "            scores = {threshold : [] for threshold in params_grid['pos_threshold']}\n",
        "\n",
        "            for train_index, test_index in kf.split(X):\n",
        "                X_train, X_test = X[train_index], X[test_index]\n",
        "                y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "                # Create and fit the model\n",
        "                model = create_shallow_network(input_dim, hidden_layers, \\\n",
        "                                                dropout_rate, learning_rate)\n",
        "\n",
        "                model.fit(X_train, y_train, epochs=10, verbose=0, class_weight=class_weights_dict)\n",
        "\n",
        "                # Sigmoid output\n",
        "                y_pred_raw = model.predict(X_test)\n",
        "\n",
        "                # Predicted labels based on sigmoid output\n",
        "                for threshold in params_grid['pos_threshold']:\n",
        "                  y_pred = (y_pred_raw > threshold).astype(int).squeeze()\n",
        "\n",
        "                  # Calculate performance based on selected score\n",
        "                  if val_score == 'accuracy':\n",
        "                    score = accuracy_score(y_test, y_pred)\n",
        "\n",
        "                  elif val_score == 'recall':\n",
        "                    score = recall_score(y_test, y_pred)\n",
        "\n",
        "                  elif val_score == 'f1_score':\n",
        "                    score = f1_score(y_test, y_pred)\n",
        "\n",
        "                  elif val_score == 'roc_auc':\n",
        "                    score = roc_auc_score(y_test, y_pred_raw)\n",
        "\n",
        "                  else:\n",
        "                    print(f'ERROR: unexpected validation score {val_score}.')\n",
        "                    print('Select one of: accuracy, recall, f1_score')\n",
        "\n",
        "                  scores[threshold].append(score)\n",
        "\n",
        "                  progress += 1\n",
        "\n",
        "                  clear_output(wait=True)\n",
        "                  print(f'Cross-validation progress: {progress / total_runs * 100:.2f}%')\n",
        "\n",
        "                # Best average score across all folds\n",
        "                best_threshold = max(scores, key=lambda thr: np.mean(scores[thr]))\n",
        "                best_average_score = np.mean(scores[best_threshold])\n",
        "\n",
        "                # Check if current model settings beat the current best\n",
        "                if best_average_score > best_score:\n",
        "                    best_score = best_average_score\n",
        "                    best_params = {'hidden_layers': hidden_layers,\n",
        "                                  'dropout_rate': dropout_rate,\n",
        "                                  'learning_rate': learning_rate,\n",
        "                                  'pos_threshold': best_threshold}\n",
        "\n",
        "  # Print best parameters and their score\n",
        "  if verbose:\n",
        "    print(f\"\\nBest Score: {best_score:.4f}\")\n",
        "    print(\"Best Parameters:\", best_params)\n",
        "\n",
        "  return best_params"
      ],
      "metadata": {
        "id": "nvWC2RMgpMF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up model dictionary for ease of reuse.\n",
        "# Only models which do not need cross-validation are included in this.\n",
        "# Models with cross-validation are handled on an individual basis.\n",
        "\n",
        "models_dict = {\n",
        "    'LogisticRegression' : LogisticRegression(max_iter=1000, class_weight=class_weights_dict),\n",
        "    'SVC-Linear' : SVC(class_weight='balanced', kernel='linear')\n",
        "    }\n",
        "\n",
        "# Models which do not need cross-validation.\n",
        "no_cross_val = list(models_dict.keys())"
      ],
      "metadata": {
        "id": "HKtjad033aFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting model (with potential cross validation).\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# If model requires cross-validation.\n",
        "if clf_name not in no_cross_val:\n",
        "  if clf_name == 'ShallowNetwork':\n",
        "    best_params = crossval_shallow_network(cv_folds, input_size, X_train, \\\n",
        "                                           y_train, param_grid['ShallowNetwork'],\\\n",
        "                                           val_score = val_score, verbose=True)\n",
        "\n",
        "    model = create_shallow_network(input_size, best_params['hidden_layers'], \\\n",
        "                                 best_params['dropout_rate'], best_params['learning_rate'])\n",
        "\n",
        "# If model does not require cross-validation.\n",
        "else:\n",
        "  model = models_dict[clf_name]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE1joIrK3I6_",
        "outputId": "8a4cd9bd-7927-40e6-9c0f-4c8c7e385d3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation progress: 100.00%\n",
            "\n",
            "Best Score: 0.9057\n",
            "Best Parameters: {'hidden_layers': 1, 'dropout_rate': 0.5, 'learning_rate': 0.0001, 'pos_threshold': 0.1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model on the training set.\n",
        "model.fit(X_train, y_train, class_weight=class_weights_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn0TwY8yIbhx",
        "outputId": "108bdfff-473a-46ea-f874-35525d738349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 1s 6ms/step - loss: 0.8279 - accuracy: 0.7191\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bfa98d83d00>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose best threshold manually for neural network if cross-validation happened based on ROC AUC:\n",
        "if clf_name == 'ShallowNetwork' and val_score == 'roc_auc':\n",
        "  pos_threshold = 0.5\n",
        "\n",
        "  best_params['pos_threshold'] = pos_threshold"
      ],
      "metadata": {
        "id": "CyCuYAz_8FO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Saving best hyperparameters.\n",
        "  best_params_df = pd.DataFrame([best_params])\n",
        "\n",
        "  params_output_path = os.path.join(output_dir, 'Parameters')\n",
        "\n",
        "  os.makedirs(params_output_path, exist_ok=True)\n",
        "\n",
        "  params_csv_path = os.path.join(output_dir, f'Parameters/params_{dataset_name}_{frame_selection_method}_{embedding_method}_{image_size}_{clf_name}_{val_score.replace(\"_\", \"-\")}.csv')\n",
        "\n",
        "  best_params_df.to_csv(params_csv_path, index=False)"
      ],
      "metadata": {
        "id": "o4u-3kZUATgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictions and testing"
      ],
      "metadata": {
        "id": "yMXGX5HiBOcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save predictions for each instance of the test set."
      ],
      "metadata": {
        "id": "HwjnevSxD7Mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions.\n",
        "y_pred_raw = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKFnUeaM5ROL",
        "outputId": "7cd52d6d-02cc-47c7-9407-ae1ad788dced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare DataFrame with video names and predictions.\n",
        "predictions_df = pd.DataFrame({\n",
        "    'video': video_names_test,\n",
        "    'prediction': y_pred_raw.squeeze(),\n",
        "    'label' : y_test\n",
        "})\n",
        "\n",
        "# Create predictions output directory.\n",
        "pred_output_path = os.path.join(output_dir, 'Predictions')\n",
        "os.makedirs(params_output_path, exist_ok=True)\n",
        "\n",
        "# Save predictions.\n",
        "predictions_csv_path = os.path.join(output_dir, f'pred_{dataset_name}_{frame_selection_method}_{embedding_method}_{image_size}_{clf_name}_{val_score.replace(\"_\", \"-\")}.csv')\n",
        "predictions_df.to_csv(predictions_csv_path, index=False)"
      ],
      "metadata": {
        "id": "jSTHAae23wqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy prediction files to Drive.\n",
        "for file in os.listdir(output_dir):\n",
        "  source_dir = os.path.join(output_dir, file)\n",
        "\n",
        "  if file.startswith('pred'):   # Only consider prediction outputs.\n",
        "    dataset = file.split('_')[1]\n",
        "    data_dir_name = dataset_dict[dataset]\n",
        "\n",
        "    drive_output_dir = f\"/content/drive/My Drive/UvA/M Thesis/Data/Results/Predictions\"\n",
        "\n",
        "    if not os.path.exists(drive_output_dir):\n",
        "      os.makedirs(drive_output_dir)\n",
        "\n",
        "    destination = f'{drive_output_dir}/{file}'\n",
        "\n",
        "    # Overwrite existing file.\n",
        "    if os.path.exists(destination):\n",
        "      os.remove(destination)\n",
        "\n",
        "    shutil.copy(source_dir, destination)\n",
        "\n",
        "for file in os.listdir(f'{output_dir}/Parameters'):\n",
        "  source_dir = os.path.join(f'{output_dir}/Parameters', file)\n",
        "\n",
        "  if file.startswith('params'):   # Only consider parameter outputs.\n",
        "    dataset = file.split('_')[1]\n",
        "    data_dir_name = dataset_dict[dataset]\n",
        "\n",
        "    drive_output_dir = f\"/content/drive/My Drive/UvA/M Thesis/Data/Results/Parameters\"\n",
        "\n",
        "    if not os.path.exists(drive_output_dir):\n",
        "      os.makedirs(drive_output_dir)\n",
        "\n",
        "    destination = f'{drive_output_dir}/{file}'\n",
        "\n",
        "    # Overwrite existing file.\n",
        "    if os.path.exists(destination):\n",
        "      os.remove(destination)\n",
        "\n",
        "    shutil.copy(source_dir, destination)"
      ],
      "metadata": {
        "id": "5ABTeEmc9UCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification report on the complete test set"
      ],
      "metadata": {
        "id": "B6eZ4Eg9EKAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn sigmoid predictions into binary ones in case of a network.\n",
        "if clf_name == 'ShallowNetwork':\n",
        "  y_pred = (y_pred_raw > best_params['pos_threshold']).astype(int).squeeze()\n",
        "\n",
        "else:\n",
        "  y_pred = y_pred_raw"
      ],
      "metadata": {
        "id": "pKqRVkms8oy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Producing classification report.\n",
        "report = classification_report(y_test, y_pred, target_names=['No attack', 'Attack'])\n",
        "\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_4E06J24Gm7",
        "outputId": "f36617d3-d7c5-45c5-97a5-7c8f0c478861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   No attack       0.93      0.88      0.90       160\n",
            "      Attack       0.23      0.38      0.29        16\n",
            "\n",
            "    accuracy                           0.83       176\n",
            "   macro avg       0.58      0.62      0.59       176\n",
            "weighted avg       0.87      0.83      0.85       176\n",
            "\n"
          ]
        }
      ]
    }
  ]
}